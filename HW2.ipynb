{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2: Морфологические парсеры\n",
    "### Такташева Катя\n",
    "#### Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = ['word', 'POS']\n",
    "\n",
    "\n",
    "def to_pandas(text):\n",
    "    \"\"\"\n",
    "    converts annotated text to pandas dataframe\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    df = [word.split('_') for word in words]\n",
    "    return pd.DataFrame(df, columns=COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве списка тэгов возьмем самый узкий: не будет разделять все формы глаголов (инфинитив, причастия, деепричастия), формы прилагательных (некоторые таггеры размечают сравнительные и краткие формы), местоимения и др."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_names(tag, lang='ru'):\n",
    "    \"\"\"\n",
    "    convert all tags to a uniform standart\n",
    "    \"\"\"\n",
    "    transform = {}\n",
    "    tag = str(tag)\n",
    "    if tag not in transform:\n",
    "        if 'CONJ' in tag or 'CC' in tag:\n",
    "            transform[tag] = 'CONJ'\n",
    "        elif tag == 'PROPN':\n",
    "            transform[tag] = 'NOUN'\n",
    "        elif tag.startswith('ADJ') or tag in ['A', 'JJ', 'COMP']:\n",
    "            transform[tag] = 'ADJ'\n",
    "        elif 'PRO' in tag or tag in ['PRP', 'EX', 'PRP$', 'PRP', 'WP']:\n",
    "            transform[tag] = 'PRON'\n",
    "        elif tag.startswith('V') or tag == 'MD':\n",
    "            transform[tag] = 'VERB'\n",
    "        elif tag in ['AUX', 'INFN', 'PRED', 'GRND']:\n",
    "            transform[tag] = 'VERB'\n",
    "        elif tag in ['ADP', 'PR', 'IN', 'RP']:\n",
    "            transform[tag] = 'PREP'\n",
    "        elif tag.startswith('AD') or tag.endswith('RB'):\n",
    "            transform[tag] = 'ADVB'\n",
    "        elif tag.startswith('NN') or tag == 'S':\n",
    "            transform[tag] = 'NOUN'\n",
    "        elif tag in ['PART', 'PRT', 'TO']:\n",
    "            transform[tag] = 'PRCL'\n",
    "        elif tag == 'DT':\n",
    "            transform[tag] = 'DET'\n",
    "    if lang == 'ru' and 'DET' not in transform:\n",
    "        transform['DET'] = 'PRON'\n",
    "    return transform[tag] if tag in transform else tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ru.txt', encoding='utf-8') as fid:\n",
    "    ru_text = fid.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('en.txt', encoding='utf-8') as fid:\n",
    "    en_text = fid.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Russian: 168 words\n",
      "English: 131 words\n"
     ]
    }
   ],
   "source": [
    "print(f'Russian: {len(ru_text.split())} words')\n",
    "print(f'English: {len(en_text.split())} words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Russian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ты белых лебедей кормила , Откинув тяжесть черных кос … Я рядом плыл ; сошлись кормила ; Закатный луч был странно кос . Вдруг лебедей метнулась пара … Не знаю , чья была вина … Закат замлел за дымкой пара , Алея , как поток вина . Мгновенья двигались и стали , Лишь ты паришь , свой свет струя … Меж тем в реке – из сизой стали Влачится за струей струя . Небесное светило было закрыто дождевыми тучами , а еще вчера оно так ярко и ласково нам светило . Если б мыло приходило по утрам ко мне в кровать и само меня бы мыло , хорошо бы это было . Мы ели , ели ершей у ели . Их еле-еле у ели доели . Вам нужно тщательнее следить за вашим рабочим местом . Рабочим было трудно завершить строительство во время пандемии из-за закрытия всех магазинов . Плывут по озеру пироги – На остров нет другой дороги . Любишь кушать пироги – Печь их маме помоги . '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что тут сложного?**\n",
    "Как тут, так и в английском тексте присутсвует много морфологически омонимичных слов - т.е. слов разных частей речи, которые сложно распарсить на, собственно, части речи без контекста. Поскольку большинство тэггеров не смотрят на контекст, задача тэггинга таких единиц предстваляет проблему.\n",
    "\n",
    "**Примеры слов:**\n",
    "\n",
    "В русском:\n",
    "- *струя* (дееприч., ср. свет струя) - *струя* (сущ., ср. струя реки)\n",
    "- *ели* (гл. мы ели суп) - *ели* (сущ. им/вин.п. мн.ч., ср. зеленые ели)\n",
    "- *рабочим* (сущ. д.п.мн.ч./тв.п.ед.ч. , ср. гордиться рабочим, дать рабочим задание) - *рабочим* (прил. тв.п.ед.ч. он гордился своим рабочим местом)\n",
    "- тут еще много других\n",
    "\n",
    "В английском:\n",
    "- *cook* (гл., ср. to cook fish) - *cook* (прил., ср. a cook book) - *cook* (сущ. ср. he's a great cook)\n",
    "- *well* (сущ., to fall in a well) - *well* (наречие, ср. well done)\n",
    "- и другие"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hand-parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ru_text.txt', encoding='utf-8') as fid:\n",
    "    ru_answers = fid.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ты</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>белых</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>лебедей</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>кормила</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Печь</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>их</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>маме</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>помоги</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word    POS\n",
       "0         Ты   PRON\n",
       "1      белых    ADJ\n",
       "2    лебедей   NOUN\n",
       "3    кормила   VERB\n",
       "4          ,  PUNCT\n",
       "..       ...    ...\n",
       "163     Печь   VERB\n",
       "164       их   PRON\n",
       "165     маме   NOUN\n",
       "166   помоги   VERB\n",
       "167        .  PUNCT\n",
       "\n",
       "[168 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_df = to_pandas(ru_answers)\n",
    "ru_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pymorphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymorphy_df = []\n",
    "for token in [morph.parse(word)[0] for word in ru_text.split()]:\n",
    "    word = token.word\n",
    "    POS = token.tag.POS\n",
    "    if POS is None:\n",
    "        POS = 'PUNCT'\n",
    "    pymorphy_df.append((word, POS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ты</td>\n",
       "      <td>NPRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>белых</td>\n",
       "      <td>ADJF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>лебедей</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>кормила</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>печь</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>их</td>\n",
       "      <td>NPRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>маме</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>помоги</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word    POS\n",
       "0         ты   NPRO\n",
       "1      белых   ADJF\n",
       "2    лебедей   NOUN\n",
       "3    кормила   VERB\n",
       "4          ,  PUNCT\n",
       "..       ...    ...\n",
       "163     печь   NOUN\n",
       "164       их   NPRO\n",
       "165     маме   NOUN\n",
       "166   помоги   VERB\n",
       "167        .  PUNCT\n",
       "\n",
       "[168 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pymorphy_df = pd.DataFrame(pymorphy_df, columns=COLUMNS)\n",
    "pymorphy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MyStem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_df = []\n",
    "for token in [m.analyze(word.strip()) for word in ru_text.split()]:\n",
    "    if 'analysis' in token[0]:\n",
    "        word = token[0]['text']\n",
    "        POS = token[0]['analysis'][0]['gr'].replace('=', ',').split(',', maxsplit=1)[0]\n",
    "    elif token[0]['text'] != ' ':\n",
    "        word = token[0]['text']\n",
    "        POS = 'PUNCT'\n",
    "    mystem_df.append((word, POS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ты</td>\n",
       "      <td>SPRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>белых</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>лебедей</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>кормила</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,\\n</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Печь</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>их</td>\n",
       "      <td>SPRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>маме</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>помоги</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word    POS\n",
       "0         Ты   SPRO\n",
       "1      белых      A\n",
       "2    лебедей      S\n",
       "3    кормила      V\n",
       "4        ,\\n  PUNCT\n",
       "..       ...    ...\n",
       "163     Печь      S\n",
       "164       их   SPRO\n",
       "165     маме      S\n",
       "166   помоги      V\n",
       "167        .  PUNCT\n",
       "\n",
       "[168 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_df = pd.DataFrame(mystem_df, columns=COLUMNS)\n",
    "mystem_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    Doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = Segmenter()\n",
    "text = Doc(ru_text)\n",
    "text.segment(segmenter)\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "text.tag_morph(morph_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "natasha_df = []\n",
    "for sent in text.sents:\n",
    "    parsed = sent.morph.tokens\n",
    "    for token in parsed:\n",
    "        word = token.text\n",
    "        POS = token.pos\n",
    "        natasha_df.append((word, POS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ты</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>белых</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>лебедей</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>кормила</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Печь</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>их</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>маме</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>помоги</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word    POS\n",
       "0         Ты   PRON\n",
       "1      белых    ADJ\n",
       "2    лебедей   NOUN\n",
       "3    кормила   VERB\n",
       "4          ,  PUNCT\n",
       "..       ...    ...\n",
       "163     Печь  PROPN\n",
       "164       их   PRON\n",
       "165     маме   NOUN\n",
       "166   помоги   VERB\n",
       "167        .  PUNCT\n",
       "\n",
       "[168 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natasha_df = pd.DataFrame(natasha_df, columns=COLUMNS)\n",
    "natasha_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "\n",
    "Приводим к одному виду:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymorphy_df['POS'] = pymorphy_df['POS'].apply(convert_names)\n",
    "mystem_df['POS'] = mystem_df['POS'].apply(convert_names)\n",
    "natasha_df['POS'] = natasha_df['POS'].apply(convert_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyMorphy: 0.9345238095238095\n",
      "MyStem: 0.8333333333333334\n",
      "Natasha: 0.8214285714285714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "print(f\"PyMorphy: {accuracy_score(pymorphy_df['POS'].tolist(), ru_df['POS'].tolist())}\")\n",
    "print(f\"MyStem: {accuracy_score(mystem_df['POS'].tolist(), ru_df['POS'].tolist())}\")\n",
    "print(f\"Natasha: {accuracy_score(natasha_df['POS'].tolist(), ru_df['POS'].tolist())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The other day I have bought a new cook book. It is awesome. There are lots of great recipes in it and I can't wait to cook them all. \\nBefore you travel in a different country you need to make sure you book a hotel, else you might end up on the street.\\nMy neighbours told us a scary story about a woman who fell in the well. \\nI was not feeling well after hearing it.\\nYou need to bow every time the queen walks in or it will cost you your head.\\nHe always wanted to learn how to shoot an arrow, but didn't manage to buy a bow.\\nHe was our only hope in getting out of town.\\nLet's hope we can save some money for a ride home.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hand-parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('en_text.txt', encoding='utf-8') as fid:\n",
    "    en_answers = fid.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>day</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>for</td>\n",
       "      <td>PREP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>ride</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>home</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word    POS\n",
       "0      The    DET\n",
       "1    other    ADJ\n",
       "2      day   NOUN\n",
       "3        I   PRON\n",
       "4     have   VERB\n",
       "..     ...    ...\n",
       "141    for   PREP\n",
       "142      a    DET\n",
       "143   ride   NOUN\n",
       "144   home   NOUN\n",
       "145      .  PUNCT\n",
       "\n",
       "[146 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_df = to_pandas(en_answers)\n",
    "en_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katya/opt/anaconda3/lib/python3.7/site-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.0) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.2). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_df = []\n",
    "for token in nlp(en_text):\n",
    "    word = token.text\n",
    "    POS = token.pos_\n",
    "    if POS != 'SPACE':\n",
    "        spacy_df.append((word, POS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>day</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have</td>\n",
       "      <td>AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>for</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>ride</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>home</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word    POS\n",
       "0      The    DET\n",
       "1    other    ADJ\n",
       "2      day   NOUN\n",
       "3        I   PRON\n",
       "4     have    AUX\n",
       "..     ...    ...\n",
       "141    for    ADP\n",
       "142      a    DET\n",
       "143   ride   NOUN\n",
       "144   home   NOUN\n",
       "145      .  PUNCT\n",
       "\n",
       "[146 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_df = pd.DataFrame(spacy_df, columns=COLUMNS)\n",
    "spacy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_df = []\n",
    "for i in nltk.word_tokenize(en_text):\n",
    "    parsed = nltk.pos_tag([i],tagset='universal')\n",
    "    word = parsed[0][0]\n",
    "    POS = parsed[0][1]\n",
    "    if POS in punctuation:\n",
    "        POS = 'PUNCT'\n",
    "    nltk_df.append((word, POS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>day</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>for</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>ride</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>home</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word    POS\n",
       "0      The    DET\n",
       "1    other    ADJ\n",
       "2      day   NOUN\n",
       "3        I   PRON\n",
       "4     have   VERB\n",
       "..     ...    ...\n",
       "141    for    ADP\n",
       "142      a    DET\n",
       "143   ride   NOUN\n",
       "144   home   NOUN\n",
       "145      .  PUNCT\n",
       "\n",
       "[146 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_df = pd.DataFrame(nltk_df, columns=COLUMNS)\n",
    "nltk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-16 18:04:49,993 loading file /Users/katya/.flair/models/en-pos-ontonotes-v0.5.pt\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "import re\n",
    "\n",
    "tagger = SequenceTagger.load('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_df = []\n",
    "for sent in nltk.sent_tokenize(en_text):\n",
    "    sentence = Sentence(sent)\n",
    "    tagger.predict(sentence)\n",
    "    parsed = sentence.to_tagged_string().split()\n",
    "    for i in range(0, len(parsed)-1, 2):\n",
    "        word, POS = parsed[i], re.sub('<|>', '', parsed[i+1])\n",
    "        if POS in punctuation:\n",
    "            POS = 'PUNCT'\n",
    "        flair_df.append((word, POS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>day</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>for</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>a</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>ride</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>home</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word    POS\n",
       "0      The     DT\n",
       "1    other     JJ\n",
       "2      day     NN\n",
       "3        I    PRP\n",
       "4     have    VBP\n",
       "..     ...    ...\n",
       "141    for     IN\n",
       "142      a     DT\n",
       "143   ride     NN\n",
       "144   home     RB\n",
       "145      .  PUNCT\n",
       "\n",
       "[146 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flair_df = pd.DataFrame(flair_df, columns=COLUMNS)\n",
    "flair_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "Приводим к одному виду:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_df['POS'] = spacy_df['POS'].apply(convert_names, lang='en')\n",
    "nltk_df['POS'] = nltk_df['POS'].apply(convert_names, lang='en')\n",
    "flair_df['POS'] = flair_df['POS'].apply(convert_names, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy: 0.9931506849315068\n",
      "NLTK: 0.815068493150685\n",
      "Flair: 0.9726027397260274\n"
     ]
    }
   ],
   "source": [
    "print(f\"SpaCy: {accuracy_score(spacy_df['POS'].tolist(), en_df['POS'].tolist())}\")\n",
    "print(f\"NLTK: {accuracy_score(nltk_df['POS'].tolist(), en_df['POS'].tolist())}\")\n",
    "print(f\"Flair: {accuracy_score(flair_df['POS'].tolist(), en_df['POS'].tolist())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier improvement (?)\n",
    "\n",
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_smooth_bins(data, n=1000):\n",
    "    smooth = []\n",
    "    for label in ['pos', 'neg']:\n",
    "        smooth.append(data[data['class']==label].sample(n//2))\n",
    "    return pd.concat(smooth, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film_id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>978935</td>\n",
       "      <td>фильм « исчезновение » я ждать , так как трейл...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1207666</td>\n",
       "      <td>давно не писать рецензия на фильм . 4 год , ес...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>808639</td>\n",
       "      <td>' дуpaк ' из тот фильмoть , кoтopый бить oбухo...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>301</td>\n",
       "      <td>исполниться 20 год « матрица » — коктейль от р...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>680149</td>\n",
       "      <td>основной маркёр это фильм – он оригинальный на...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>797840</td>\n",
       "      <td>не радовать . \\n\\n зачем главное герой сделать...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>273302</td>\n",
       "      <td>фильм от режиссёр великий произведение кинемат...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>5492</td>\n",
       "      <td>« можно стереть любовь из память . выкинуть из...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>381</td>\n",
       "      <td>фильм - взгяд на происходить в жизнь событие ч...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>841147</td>\n",
       "      <td>некоторый человек цивилизация утомлять настоль...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      film_id                                               text class\n",
       "0      978935  фильм « исчезновение » я ждать , так как трейл...   pos\n",
       "1     1207666  давно не писать рецензия на фильм . 4 год , ес...   pos\n",
       "2      808639  ' дуpaк ' из тот фильмoть , кoтopый бить oбухo...   pos\n",
       "3         301  исполниться 20 год « матрица » — коктейль от р...   pos\n",
       "4      680149  основной маркёр это фильм – он оригинальный на...   pos\n",
       "...       ...                                                ...   ...\n",
       "9995   797840  не радовать . \\n\\n зачем главное герой сделать...   neg\n",
       "9996   273302  фильм от режиссёр великий произведение кинемат...   neg\n",
       "9997     5492  « можно стереть любовь из память . выкинуть из...   neg\n",
       "9998      381  фильм - взгяд на происходить в жизнь событие ч...   neg\n",
       "9999   841147  некоторый человек цивилизация утомлять настоль...   neg\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('reviews.csv', delimiter=',')\n",
    "reviews = get_smooth_bins(reviews, 10000)\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    5000\n",
       "pos    5000\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = np.split(reviews.sample(frac=1), [int(.80*len(reviews))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sentences: 8000\n",
      "Test sentences: 2000\n"
     ]
    }
   ],
   "source": [
    "print(f'Train sentences: {len(train)}')\n",
    "print(f'Test sentences: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    4001\n",
       "neg    3999\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    1001\n",
       "pos     999\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем улучшить качество классификатора из прошлой домашки, будем брать биграммы и триграммы следующих паттернов:\n",
    "- (не +) прилагательное ((не) плохой, (не) хороший)\n",
    "- (не +) наречие ((не) плохо, (не) хорошо)\n",
    "- (не +) наречие + прилагательное ((не) очень плохой)\n",
    "- (не +) наречие + наречие ((не) очень хорошо)\n",
    "\n",
    "Как кажется, это самые оценточные коллокации, которые должны самый большой вклад в \"точность\" словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_grams(text):\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    n_grams = []\n",
    "    for i, sent in enumerate(doc.sents):\n",
    "        tokens = sent.text.split()\n",
    "        analysis = [morph.parse(t)[0].tag.POS for t in tokens]\n",
    "        for j, an in enumerate(analysis[:-1]):\n",
    "            if tokens[j] == 'не':\n",
    "                if analysis[j+1] == 'ADJF':\n",
    "                    n_grams.append((' '.join((tokens[j], tokens[j+1]))))\n",
    "                elif analysis[j+1] == 'ADVB':\n",
    "                    try:\n",
    "                        if analysis[j+2] == 'ADJF'or analysis[j+2] == 'ADVB':\n",
    "                            n_grams.append((' '.join((tokens[j], tokens[j+1], tokens[j+2]))))\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "            elif an == 'ADJF':\n",
    "                if analysis[j+1] == 'NOUN':\n",
    "                    n_grams.append(' '.join((tokens[j], tokens[j+1])))\n",
    "            elif an == 'ADVB':\n",
    "                if analysis[j+1] == 'ADJF' or analysis[j+1] == 'ADVB':\n",
    "                    n_grams.append(' '.join((tokens[j], tokens[j+1])))\n",
    "    return n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "ru_stopwords = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, lemmatize=False):\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        if word.isalpha() and word not in ru_stopwords:\n",
    "            if lemmatize:\n",
    "                word = morph.parse(word)[0].normal_form\n",
    "            words.append(word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(pos_words, neg_words):\n",
    "    tone_dict = {}\n",
    "    for word in pos_words:\n",
    "        tone_dict[word] = 'pos'\n",
    "    for word in neg_words:\n",
    "        tone_dict[word] = 'neg'\n",
    "        \n",
    "    return tone_dict\n",
    "\n",
    "\n",
    "def get_tone_words(data, min_count=10):\n",
    "    \n",
    "    dic = {'pos': Counter(),\n",
    "           'neg': Counter()}\n",
    "    \n",
    "    print('Computing frequency dict...')\n",
    "    for idx, review in tqdm(data.iterrows(), total=len(data)):\n",
    "        dic[review['class']] += Counter(preprocess(review['text']))\n",
    "        dic[review['class']] += Counter(find_grams(review['text']))\n",
    "            \n",
    "    negative = set([i[0] for i in dic['neg'].most_common() if i[1] >= min_count])\n",
    "    positive = set([i[0] for i in dic['pos'].most_common() if i[1] >= min_count])\n",
    "    \n",
    "    \n",
    "    \n",
    "    intersect = positive.intersection(negative)\n",
    "    for i in intersect:\n",
    "        positive.discard(i)\n",
    "        negative.discard(i)\n",
    "    \n",
    "    #min_size = min((len(positive), len(negative)))  # по-хорошему надо сравнять размеры классов, но\n",
    "    #positive = list(positive)[:min_size]            # т.к. у нас довольно мало данных это сильно уменьшает\n",
    "    #negative = list(negative)[:min_size]            # размер словаря и => точность классификатора\n",
    "    \n",
    "    print(f'No intersection: {set(positive).isdisjoint(set(negative))}')\n",
    "    print(f'Positive: {len(positive)}')\n",
    "    print(f'Negative: {len(negative)}')\n",
    "                   \n",
    "    return create_dict(positive, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing frequency dict...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a383e3b3ec074f74a3be49cf5d11f758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No intersection: True\n",
      "Positive: 276\n",
      "Negative: 206\n"
     ]
    }
   ],
   "source": [
    "tone_dict = get_tone_words(train, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(review):\n",
    "    review_class = Counter()\n",
    "    words = preprocess(review)\n",
    "    for word in words:\n",
    "        if word in tone_dict:\n",
    "            review_class[tone_dict[word]] += 1 \n",
    "    return review_class.most_common()[0][0] if len(review_class) > 0 else 'pos'\n",
    "\n",
    "\n",
    "def make_predictions(test):\n",
    "    predictions = []\n",
    "    for idx, x in test.iterrows():\n",
    "        pred = classify_review(x['text'])\n",
    "        predictions.append(pred)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67\n"
     ]
    }
   ],
   "source": [
    "prediction = make_predictions(test[['film_id', 'text']])\n",
    "print(accuracy_score(prediction, test[['class']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь со сбалансированной выборкой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def balance_classes(data):\n",
    "    balanced = []\n",
    "    classes = data['class'].unique().tolist()\n",
    "    size = data['class'].value_counts().min()\n",
    "    for cl in classes:\n",
    "        balanced.append(data[data['class']==cl].sample(size))\n",
    "    return shuffle(pd.concat(balanced, ignore_index=True))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_b = balance_classes(train)\n",
    "test_b = balance_classes(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    3999\n",
       "pos    3999\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_b['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    999\n",
       "pos    999\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_b['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing frequency dict...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059da9e00d774c28b594e5a9812122b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7998.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No intersection: True\n",
      "Positive: 276\n",
      "Negative: 207\n"
     ]
    }
   ],
   "source": [
    "tone_dict = get_tone_words(train_b, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6706706706706707\n"
     ]
    }
   ],
   "source": [
    "prediction = make_predictions(test_b[['film_id', 'text']])\n",
    "print(accuracy_score(prediction, test_b[['class']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, качество, конечно, улучшилось, но не очень сильно. Можно добавить к словарю больше разных коллокаций"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
