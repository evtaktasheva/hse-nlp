{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjonrkSaIteT",
        "outputId": "887c6225-985c-4011-8c61-1ead4d63f973"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGdhl9b6I9Yc",
        "outputId": "a1b1c9c2-09db-4824-b5a6-09cd9a1e077d"
      },
      "source": [
        "%cd /content/drive/MyDrive/hse_nlp/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/hse_nlp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3LyVxpRHDsI"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JxOCuC3KGL6"
      },
      "source": [
        "# 1. Данные\n",
        "Возьмем [датасет](https://www.kaggle.com/harishcscode/all-news-articles-from-home-page-media-house) с новостями CNN с Кэггла\n",
        "\n",
        "Посмотрим на него:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKOOfgehJHLd"
      },
      "source": [
        "data = pd.read_csv('cnn.csv', index_col=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "NHiBT86OJ8j5",
        "outputId": "a686dbf2-d157-47c7-e9ab-962c2765c523"
      },
      "source": [
        "data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>KEYWORDS</th>\n",
              "      <th>SUMMARY</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>URL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['energy', 'sugars', 'bars', 'grams', 'syrup',...</td>\n",
              "      <td>Story highlights Don't be fooled by the word \"...</td>\n",
              "      <td>Story highlights Don't be fooled by the word \"...</td>\n",
              "      <td>Are energy bars healthy?</td>\n",
              "      <td>https://www.cnn.com/2017/08/25/health/energy-b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['facebook', 'whats', 'world', 'unfolds', 'tam...</td>\n",
              "      <td>Chat with us in Facebook Messenger.\\nFind out ...</td>\n",
              "      <td>Chat with us in Facebook Messenger. Find out w...</td>\n",
              "      <td>Tamagotchi is back</td>\n",
              "      <td>http://www.cnn.com/videos/cnnmoney/2017/10/10/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['jedi', 'shots', 'rey', 'force', 'wars', 'sta...</td>\n",
              "      <td>ESPN's \"Monday Night Football\" had bears, viki...</td>\n",
              "      <td>ESPN's \"Monday Night Football\" had bears, viki...</td>\n",
              "      <td>'Star Wars: The Last Jedi' trailer debuts on '...</td>\n",
              "      <td>http://money.cnn.com/2017/10/09/media/star-war...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['clients', 'art', 'science', 'scent', 'collid...</td>\n",
              "      <td>Lyn Harris' independent space, Perfumer H , in...</td>\n",
              "      <td>This feature is part of ' Details ,' a new ser...</td>\n",
              "      <td>Art and science collide in this one-of-a-kind ...</td>\n",
              "      <td>https://www.cnn.com/style/article/details-perf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['akufoaddo', 'tanker', 'incidents', 'dozens',...</td>\n",
              "      <td>(CNN) A tanker exploded near a gas station in ...</td>\n",
              "      <td>(CNN) A tanker exploded near a gas station in ...</td>\n",
              "      <td>Seven killed, dozens injured in Ghana tanker e...</td>\n",
              "      <td>https://www.cnn.com/2017/10/08/africa/ghana-ta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>938</th>\n",
              "      <td>['facebook', 'actor', 'whats', 'movie', 'world...</td>\n",
              "      <td>Chat with us in Facebook Messenger.\\nFind out ...</td>\n",
              "      <td>Chat with us in Facebook Messenger. Find out w...</td>\n",
              "      <td>Police take shot at actor on movie set</td>\n",
              "      <td>https://www.cnn.com/videos/us/2017/10/04/polic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>['races', 'danelle', 'mph', 'blind', 'life', '...</td>\n",
              "      <td>Photos: Blind skier puts her life in her husba...</td>\n",
              "      <td>(CNN) Danelle Umstead can't see when she skis ...</td>\n",
              "      <td>Blind skier races up to 70 mph</td>\n",
              "      <td>https://www.cnn.com/2016/12/16/health/turning-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940</th>\n",
              "      <td>['knew', 'harvey', 'harassed', 'hollywood', 'a...</td>\n",
              "      <td>Journalist Lauren Sivan says Hollywood mogul H...</td>\n",
              "      <td>Journalist Lauren Sivan says Hollywood mogul H...</td>\n",
              "      <td>Reporter accuses Weinstein of sexual advances</td>\n",
              "      <td>https://www.cnn.com/videos/entertainment/2017/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>['cookies', 'continuing', 'information', 'term...</td>\n",
              "      <td>By continuing to browse our site you agree to ...</td>\n",
              "      <td>By continuing to browse our site you agree to ...</td>\n",
              "      <td>Photos of the Times Square even locals love</td>\n",
              "      <td>http://www.cnn.com/travel/gallery/photos-times...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>942</th>\n",
              "      <td>['merkel', 'cap', 'party', 'limit', 'parties',...</td>\n",
              "      <td>(CNN) German Chancellor Angela Merkel has agre...</td>\n",
              "      <td>(CNN) German Chancellor Angela Merkel has agre...</td>\n",
              "      <td>Merkel changes tune on German refugee cap</td>\n",
              "      <td>https://www.cnn.com/2017/10/09/europe/germany-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>943 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              KEYWORDS  ...                                                URL\n",
              "0    ['energy', 'sugars', 'bars', 'grams', 'syrup',...  ...  https://www.cnn.com/2017/08/25/health/energy-b...\n",
              "1    ['facebook', 'whats', 'world', 'unfolds', 'tam...  ...  http://www.cnn.com/videos/cnnmoney/2017/10/10/...\n",
              "2    ['jedi', 'shots', 'rey', 'force', 'wars', 'sta...  ...  http://money.cnn.com/2017/10/09/media/star-war...\n",
              "3    ['clients', 'art', 'science', 'scent', 'collid...  ...  https://www.cnn.com/style/article/details-perf...\n",
              "4    ['akufoaddo', 'tanker', 'incidents', 'dozens',...  ...  https://www.cnn.com/2017/10/08/africa/ghana-ta...\n",
              "..                                                 ...  ...                                                ...\n",
              "938  ['facebook', 'actor', 'whats', 'movie', 'world...  ...  https://www.cnn.com/videos/us/2017/10/04/polic...\n",
              "939  ['races', 'danelle', 'mph', 'blind', 'life', '...  ...  https://www.cnn.com/2016/12/16/health/turning-...\n",
              "940  ['knew', 'harvey', 'harassed', 'hollywood', 'a...  ...  https://www.cnn.com/videos/entertainment/2017/...\n",
              "941  ['cookies', 'continuing', 'information', 'term...  ...  http://www.cnn.com/travel/gallery/photos-times...\n",
              "942  ['merkel', 'cap', 'party', 'limit', 'parties',...  ...  https://www.cnn.com/2017/10/09/europe/germany-...\n",
              "\n",
              "[943 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EziI45MuVWX6"
      },
      "source": [
        "Как видим, дла каждой статьи в датасете присутствует:\n",
        "- список из ~10 ключевых слов\n",
        "- саммари\n",
        "- собственно текст статьи\n",
        "- заголовок\n",
        "- ссылка\n",
        "\n",
        "\n",
        "\n",
        "Поскольку нам не нужен очеь большой корпус, возьмем первые 10 статей и посмотрим на количество токенов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDCXy8eFJ9FL"
      },
      "source": [
        "dataset = data[:10]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0M44pG_VBjH",
        "outputId": "8fd515c0-96d5-4a2e-df12-be7ac757aa0a"
      },
      "source": [
        "dataset.TEXT.apply(lambda x: len(x.split())).sum()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5718"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DoSDVuQWoi_"
      },
      "source": [
        "Ура, 6к токенов нам как раз\n",
        "\n",
        "# 2. Разметка ключевых слов\n",
        "\n",
        "### 2.1 Теперь разметим ключевые слова самостоятельно:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2fgKyKO_LqF"
      },
      "source": [
        "words = []\n",
        "for ind, text in dataset.iterrows():\n",
        "    print(text['TEXT'])\n",
        "    print(text['KEYWORDS'])\n",
        "    keywords = input('Keywords: ').split(', ')\n",
        "    words.append(keywords)\n",
        "    print()\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1IM7tStKoRo",
        "outputId": "4e98a57a-2350-44d0-ec8b-ea4105c4282d"
      },
      "source": [
        "dataset['MY_KEYWORDS'] = words"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "o6875G0_TaDg",
        "outputId": "b357da7a-85e7-4796-91fb-5599aaa2d10b"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>KEYWORDS</th>\n",
              "      <th>SUMMARY</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>URL</th>\n",
              "      <th>MY_KEYWORDS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['energy', 'sugars', 'bars', 'grams', 'syrup',...</td>\n",
              "      <td>Story highlights Don't be fooled by the word \"...</td>\n",
              "      <td>Story highlights Don't be fooled by the word \"...</td>\n",
              "      <td>Are energy bars healthy?</td>\n",
              "      <td>https://www.cnn.com/2017/08/25/health/energy-b...</td>\n",
              "      <td>[energy bar, energy, bar, nutrition, food, sna...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['facebook', 'whats', 'world', 'unfolds', 'tam...</td>\n",
              "      <td>Chat with us in Facebook Messenger.\\nFind out ...</td>\n",
              "      <td>Chat with us in Facebook Messenger. Find out w...</td>\n",
              "      <td>Tamagotchi is back</td>\n",
              "      <td>http://www.cnn.com/videos/cnnmoney/2017/10/10/...</td>\n",
              "      <td>[facebook, messenger, facebook messenger, worl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['jedi', 'shots', 'rey', 'force', 'wars', 'sta...</td>\n",
              "      <td>ESPN's \"Monday Night Football\" had bears, viki...</td>\n",
              "      <td>ESPN's \"Monday Night Football\" had bears, viki...</td>\n",
              "      <td>'Star Wars: The Last Jedi' trailer debuts on '...</td>\n",
              "      <td>http://money.cnn.com/2017/10/09/media/star-war...</td>\n",
              "      <td>[star wars, trailer, film, skywalker, jedi, re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['clients', 'art', 'science', 'scent', 'collid...</td>\n",
              "      <td>Lyn Harris' independent space, Perfumer H , in...</td>\n",
              "      <td>This feature is part of ' Details ,' a new ser...</td>\n",
              "      <td>Art and science collide in this one-of-a-kind ...</td>\n",
              "      <td>https://www.cnn.com/style/article/details-perf...</td>\n",
              "      <td>[perfumer, clients, world, scent, harris, form...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['akufoaddo', 'tanker', 'incidents', 'dozens',...</td>\n",
              "      <td>(CNN) A tanker exploded near a gas station in ...</td>\n",
              "      <td>(CNN) A tanker exploded near a gas station in ...</td>\n",
              "      <td>Seven killed, dozens injured in Ghana tanker e...</td>\n",
              "      <td>https://www.cnn.com/2017/10/08/africa/ghana-ta...</td>\n",
              "      <td>[ghana, explosion, explode, gas, station, gas ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>['spanish', 'independence', 'regions', 'meets'...</td>\n",
              "      <td>Carles Puigdemont, the President of Catalonia,...</td>\n",
              "      <td>(CNN) Pro-independence Catalans gathered on th...</td>\n",
              "      <td>Catalans' future on line as parliament meets</td>\n",
              "      <td>https://www.cnn.com/2017/10/10/europe/cataloni...</td>\n",
              "      <td>[catalonia, region, international mediation, m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>['press', 'excuse', 'secretary', 'trump', 'hou...</td>\n",
              "      <td>\"I think it's fake news, but if he did that, I...</td>\n",
              "      <td>(CNN) In a Forbes magazine interview published...</td>\n",
              "      <td>The Trump White House's 'joke' excuse</td>\n",
              "      <td>http://www.cnn.com/2017/10/10/politics/trump-j...</td>\n",
              "      <td>[trump, joke, iq, joking, secretary, president...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>['pollution', 'repeal', 'kellogg', 'asthma', '...</td>\n",
              "      <td>President Barak Obama shakes Camryn Kellogg's ...</td>\n",
              "      <td>(CNN) The days when all three of her children ...</td>\n",
              "      <td>Health impact of Trump environmental repeal</td>\n",
              "      <td>https://www.cnn.com/2017/10/10/health/health-e...</td>\n",
              "      <td>[kellog, asthma, child, air, air quality, clea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>['look', 'response', 'force', 'trump', 'tour',...</td>\n",
              "      <td>(CNN) Finally lumbering into a devastated Puer...</td>\n",
              "      <td>Michael D'Antonio is the author of the book \" ...</td>\n",
              "      <td>Trump in Puerto Rico: A narcissist's tour de f...</td>\n",
              "      <td>https://www.cnn.com/2017/10/03/opinions/trump-...</td>\n",
              "      <td>[trump, puerto rico, puerto, rico, president, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>['okunoin', 'tohoku', 'japan', 'risshakuji', '...</td>\n",
              "      <td>(CNN) — Upon hearing I would have to climb 1,0...</td>\n",
              "      <td>\\n\\n\\n\\nThis article was first published in Ju...</td>\n",
              "      <td>Yamadera Risshakuji in Tohoku: 1,015 steps to ...</td>\n",
              "      <td>https://www.cnn.com/travel/article/yamadera-te...</td>\n",
              "      <td>[temple, japan, yamadera, risshakuju, 1015, st...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            KEYWORDS  ...                                        MY_KEYWORDS\n",
              "0  ['energy', 'sugars', 'bars', 'grams', 'syrup',...  ...  [energy bar, energy, bar, nutrition, food, sna...\n",
              "1  ['facebook', 'whats', 'world', 'unfolds', 'tam...  ...  [facebook, messenger, facebook messenger, worl...\n",
              "2  ['jedi', 'shots', 'rey', 'force', 'wars', 'sta...  ...  [star wars, trailer, film, skywalker, jedi, re...\n",
              "3  ['clients', 'art', 'science', 'scent', 'collid...  ...  [perfumer, clients, world, scent, harris, form...\n",
              "4  ['akufoaddo', 'tanker', 'incidents', 'dozens',...  ...  [ghana, explosion, explode, gas, station, gas ...\n",
              "5  ['spanish', 'independence', 'regions', 'meets'...  ...  [catalonia, region, international mediation, m...\n",
              "6  ['press', 'excuse', 'secretary', 'trump', 'hou...  ...  [trump, joke, iq, joking, secretary, president...\n",
              "7  ['pollution', 'repeal', 'kellogg', 'asthma', '...  ...  [kellog, asthma, child, air, air quality, clea...\n",
              "8  ['look', 'response', 'force', 'trump', 'tour',...  ...  [trump, puerto rico, puerto, rico, president, ...\n",
              "9  ['okunoin', 'tohoku', 'japan', 'risshakuji', '...  ...  [temple, japan, yamadera, risshakuju, 1015, st...\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVdU-yhZo_WI"
      },
      "source": [
        "Уберем лишние колонки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dnMmI0w6u6q"
      },
      "source": [
        "dataset.drop(columns=['TITLE', 'URL'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz_6Ea3iXLIm"
      },
      "source": [
        "Ну и сохраним полученные данные:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "433GUUatT8T8"
      },
      "source": [
        "dataset.to_csv('cnn_kw.csv', index=False)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD-tyzTsXV9N"
      },
      "source": [
        "### 2.2 Сравним разметки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoycr0jLURpB"
      },
      "source": [
        "dataset = pd.read_csv('cnn_kw.csv')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PnmTejJZ9Dd"
      },
      "source": [
        "dataset['KEYWORDS'] = dataset['KEYWORDS'].apply(lambda x: set(eval(x)))\n",
        "dataset['MY_KEYWORDS'] = dataset['MY_KEYWORDS'].apply(lambda x: set(eval(x)))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK_HCRSudNOG"
      },
      "source": [
        "Если посмотрим на несколько примеров разметки, то увидим несколько вещей:\n",
        "\n",
        "1. В оригинальном датасете представлены только односложные слова, я же размечала и частотные словосочетания:    \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il4e0XxLbhTT",
        "outputId": "ba778654-90d4-440d-a62e-e8084baa66ab"
      },
      "source": [
        "print('ORG:', dataset.KEYWORDS.apply(lambda x: np.mean([len(i.split()) for i in x])).mean())\n",
        "print('MY:', dataset.MY_KEYWORDS.apply(lambda x: np.mean([len(i.split()) for i in x])).mean())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORG: 1.0\n",
            "MY: 1.1366880341880339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aQgS4sleIWY"
      },
      "source": [
        "2. В оригинальной разметке в качетсве частотных слов многда выделены такие вещи, которые обыяно не хочется считать за ключевые слова.. Вот например тут есть `whats`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcM9FJs0d_HT",
        "outputId": "eb1ee33d-580d-41eb-b412-040d76408b1f"
      },
      "source": [
        "dataset.KEYWORDS[1]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chat',\n",
              " 'facebook',\n",
              " 'happening',\n",
              " 'messenger',\n",
              " 'tamagotchi',\n",
              " 'unfolds',\n",
              " 'whats',\n",
              " 'world'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz-jaAjUgeSm"
      },
      "source": [
        "В целом, случаев 2 мало, а выделенные автоматически слова довольно хорошие, так что в качестве эталонной разметки возьмем объединение моей и оригинальной: так получим и словосочетания и прелести разнообразности:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6Gnjob8fCM8"
      },
      "source": [
        "dataset = dataset.assign(target=lambda x: x.KEYWORDS.values | x.MY_KEYWORDS.values)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "-cQW58z4hjZK",
        "outputId": "20aa9827-eb44-44d2-952c-ce5d384ff54b"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>KEYWORDS</th>\n",
              "      <th>SUMMARY</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>MY_KEYWORDS</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>{energy, grams, sugars, bars, bar, saturated, ...</td>\n",
              "      <td>Story highlights Don't be fooled by the word \"...</td>\n",
              "      <td>Story highlights Don't be fooled by the word \"...</td>\n",
              "      <td>{energy, sugars, bar, saturated, calories, sat...</td>\n",
              "      <td>{energy, grams, contain, fat, snacks, food, su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>{messenger, happening, facebook, chat, unfolds...</td>\n",
              "      <td>Chat with us in Facebook Messenger.\\nFind out ...</td>\n",
              "      <td>Chat with us in Facebook Messenger. Find out w...</td>\n",
              "      <td>{messenger, facebook,  chat, world, facebook m...</td>\n",
              "      <td>{messenger, happening, facebook, chat, unfolds...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>{rey, shots, trailer, debuts, football, film, ...</td>\n",
              "      <td>ESPN's \"Monday Night Football\" had bears, viki...</td>\n",
              "      <td>ESPN's \"Monday Night Football\" had bears, viki...</td>\n",
              "      <td>{trailer, franchise, red, film, jedi, skywalke...</td>\n",
              "      <td>{football, red, star, jedi, wars, skywalker, r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>{perfumer, art, harris, h, world, quite, oneof...</td>\n",
              "      <td>Lyn Harris' independent space, Perfumer H , in...</td>\n",
              "      <td>This feature is part of ' Details ,' a new ser...</td>\n",
              "      <td>{perfumer, art, perfume, harris, world, client...</td>\n",
              "      <td>{perfumer, perfume, world, oneofakind, science...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>{streetsgovernment, nana, dozens, tanker, inci...</td>\n",
              "      <td>(CNN) A tanker exploded near a gas station in ...</td>\n",
              "      <td>(CNN) A tanker exploded near a gas station in ...</td>\n",
              "      <td>{explode, government, killed, gas, incident, g...</td>\n",
              "      <td>{nana, dozens, tanker, explode, incidents, gas...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                             target\n",
              "0           0  ...  {energy, grams, contain, fat, snacks, food, su...\n",
              "1           1  ...  {messenger, happening, facebook, chat, unfolds...\n",
              "2           2  ...  {football, red, star, jedi, wars, skywalker, r...\n",
              "3           3  ...  {perfumer, perfume, world, oneofakind, science...\n",
              "4           4  ...  {nana, dozens, tanker, explode, incidents, gas...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVuFN3RxkA9q"
      },
      "source": [
        "# 3. Автоматическое извлечение ключевых слов\n",
        "\n",
        "Сначала предобработаем тексты:    \n",
        "- приведем все в нижний регистр\n",
        "- затокенизируем \n",
        "\n",
        "(для английского языка лемметизация или стемминг не очень продуктивны, так что обойдемся этим)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX4qg8JJpmwX",
        "outputId": "4329cdc8-b486-477c-bbdf-3a5a29d04c4f"
      },
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download(['punkt', 'stopwords'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxxybmUtvpHw"
      },
      "source": [
        "STOPS = stopwords.words('english')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCOfaGHipWXI"
      },
      "source": [
        "def preprocess(text):\n",
        "    return ' '.join([token.lower() for token in word_tokenize(text)])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up8gzAVep3al"
      },
      "source": [
        "dataset['tokenized'] = dataset.TEXT.apply(preprocess)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-Ot8UkDoQUQ"
      },
      "source": [
        "## 3.1 TF-IDF\n",
        "\n",
        "Сначала возьмем самый простой вариант -- TF-IDF\n",
        "\n",
        "Воспользуемся [этой](https://github.com/kavgan/nlp-in-practice/blob/master/tf-idf/Keyword%20Extraction%20with%20TF-IDF%20and%20SKlearn.ipynb) имплементацией, но заменим вывод topn ключевых слов, на топ слов, скор которых превосходит порог"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T01d_oZZoA5A",
        "outputId": "e6b3766a-ddf7-48a9-ba69-3b249528a175"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "\n",
        "\n",
        "cv = CountVectorizer(max_df=0.85, stop_words=STOPS, max_features=10000, ngram_range=(1,3))\n",
        "word_count_vector = cv.fit_transform(dataset.tokenized.tolist())\n",
        "\n",
        "tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
        "tfidf_transformer.fit(word_count_vector)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2SrI2A-wy80"
      },
      "source": [
        "def sort_coo(coo_matrix):\n",
        "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
        "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
        "\n",
        "def extract_topn_from_vector(feature_names, sorted_items, tol=0.1):\n",
        "    \"\"\"get the feature names and tf-idf score of items\"\"\"\n",
        "    \n",
        "    sorted_items = [item for item in sorted_items if item[1] > tol]  \n",
        "\n",
        "    score_vals = []\n",
        "    feature_vals = []\n",
        "\n",
        "    for idx, score in sorted_items:\n",
        "        fname = feature_names[idx]\n",
        "        \n",
        "        #keep track of feature name and its corresponding score\n",
        "        score_vals.append(round(score, 3))\n",
        "        feature_vals.append(feature_names[idx])\n",
        "\n",
        "    #create a tuples of feature,score\n",
        "    #results = zip(feature_vals,score_vals)\n",
        "    results= {}\n",
        "    for idx in range(len(feature_vals)):\n",
        "        results[feature_vals[idx]]=score_vals[idx]\n",
        "    \n",
        "    return results"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "locyj8S0w8oe"
      },
      "source": [
        "def tfidf_keywords(text, tol=0.1):\n",
        "    feature_names = cv.get_feature_names()\n",
        "    tf_idf_vector = tfidf_transformer.transform(cv.transform([text]))\n",
        "    sorted_items = sort_coo(tf_idf_vector.tocoo())\n",
        "    keywords = extract_topn_from_vector(feature_names, sorted_items, tol)\n",
        "\n",
        "    return set(keywords.keys())"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5lRgWoHytbx"
      },
      "source": [
        "Возьмем два порога 0.1 и 0.15, на них кажется получаем оптимальное количество ключевых слов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaeMyQfwy3k4"
      },
      "source": [
        "dataset['tfidf_1'] = dataset.tokenized.apply(tfidf_keywords, tol=0.1)\n",
        "dataset['tfidf_15'] = dataset.tokenized.apply(tfidf_keywords, tol=0.15)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CeeOE4ky37O",
        "outputId": "a36d2321-1c23-44f8-f62f-e084076ddcbd"
      },
      "source": [
        "print('tol=0.15:', dataset.tfidf_15[0])\n",
        "print('tol=0.1:', dataset.tfidf_1[0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tol=0.15: {'saturated fat', 'energy', 'bars', 'bar', 'saturated', 'fat'}\n",
            "tol=0.1: {'saturated fat', 'energy', 'energy bars', 'grams', 'bars', 'bar', 'saturated', 'fat', 'contain', 'nutrition', 'protein'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ei6qDVyn-k2"
      },
      "source": [
        "## 3.2 TextRank\n",
        "\n",
        "Возьмем имплементацию [отсюда](https://github.com/summanlp/textrank)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOpVDv4fjMYQ"
      },
      "source": [
        "!pip install --quiet summa"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u215YXW1m7m3"
      },
      "source": [
        "from summa.textrank import textrank\n",
        "\n",
        "\n",
        "dataset['textrank'] = dataset.TEXT.apply(lambda x: set(textrank(x, summarize_by=None).split('\\n')))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCx_637snzvk",
        "outputId": "80461ac0-15d3-4d8a-e6b5-0d1338866638"
      },
      "source": [
        "dataset.textrank[0]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'convenient source',\n",
              " 'created',\n",
              " 'equal',\n",
              " 'meal',\n",
              " 'meals',\n",
              " 'replacement aim',\n",
              " 'rice syrup',\n",
              " 'satisfy',\n",
              " 'satisfying',\n",
              " 'story highlights'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CExzwwkTzm8t"
      },
      "source": [
        "### 3.3 BERT\n",
        "\n",
        "Посмотрим на то, как с извлечением ключевых слов справляется трансформер 🌝\n",
        "\n",
        "Снова не будем изобретать велосипед и воспользуемся вот [этой имплементацией](https://github.com/MaartenGr/KeyBERT)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70clfhSPzjsK"
      },
      "source": [
        "!pip install --quiet keybert"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOaQQbvo0YeX"
      },
      "source": [
        "from keybert import KeyBERT\n",
        "\n",
        "\n",
        "kw_model = KeyBERT()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McyLdYty797g"
      },
      "source": [
        "Почему-то при указании ngram-range всегда ищутся только нграммы максимальной длины, а хочется разнообразия, поэтому сделаем так:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--O5adJ_1GiR"
      },
      "source": [
        "def bert_keywords(text, tol=0.4):\n",
        "    kw = []\n",
        "    for i in range(1,4):\n",
        "        words = kw_model.extract_keywords(text, keyphrase_ngram_range=(i,i), stop_words=STOPS, top_n=10)\n",
        "        kw.extend([word[0] for word in words if word[1] > tol])\n",
        "    return set(kw)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxTEKOUz0oMW"
      },
      "source": [
        "dataset['bert_4'] = dataset['tokenized'].apply(bert_keywords, tol=0.4)\n",
        "dataset['bert_5'] = dataset['tokenized'].apply(bert_keywords, tol=0.5)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xlkhb6P01az0"
      },
      "source": [
        "# 4. Шаблоны\n",
        "\n",
        "Выделим шаблоны, которые встречаются в таргете:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG3zDGbkI0ja",
        "outputId": "c27d03c7-b0c0-4365-a863-47fe7c008aa2"
      },
      "source": [
        "!pip install --quiet spacy==3.1\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.1.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.6 MB 69 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.1.0) (3.1.0)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.3.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.6)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.7.4.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (21.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.19.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.23.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.11.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.6.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2021.5.30)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FLq7ybIIR8c"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khtEvqsgRz4S"
      },
      "source": [
        "Опишем шаблоны:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifbJ1ExsELOX"
      },
      "source": [
        "import re\n",
        "\n",
        "\n",
        "NP = '(?:ADJ |NOUN |PROPN |VERB |ADP )*(?:NOUN|PROPN)'  # \"стандартные\" именные группы + штуки типа secretary of state, imported goods и тд\n",
        "VP = '(?:VERB |PRON |DET )*VERB'  # глагольные группы + штуки как whats и thats\n",
        "AP = '(?:ADJ |ADV )*ADJ'  # прилагательные и адъективные группы\n",
        "OT = 'NUM|ADP'  # другие вещи, не входящие в описанное выше, например цифры (ADP потому что iq размечается spacy как ADP)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz7vCW-APl5K"
      },
      "source": [
        "def check_pattern(text: str):\n",
        "    doc = nlp(text)\n",
        "    pos = ' '.join([token.pos_ for token in doc])\n",
        "    \n",
        "    patterns = []\n",
        "    for pattern in [NP, VP, AP, OT]:\n",
        "        match = re.findall(pattern, pos)\n",
        "        if not match:\n",
        "            continue\n",
        "        for p in match:\n",
        "            if len(p.split()) == len(pos.split()):\n",
        "                return text\n",
        "       \n",
        "\n",
        "def filter_kw(kw: set):\n",
        "    new_words = [check_pattern(word) for word in kw]\n",
        "    return set([w for w in new_words if w])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcs-OTA6Wmqa"
      },
      "source": [
        "Проверим, что фильтрация работает:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLbjNFufWU9p",
        "outputId": "1b774aa8-caf7-472b-ba7f-ee4b6b9e5ce9"
      },
      "source": [
        "(dataset.tfidf_1.apply(filter_kw) == dataset.tfidf_1).all()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0tJ2yQRXDKu"
      },
      "source": [
        "Ура, что-то отфильтровалось\n",
        "\n",
        "# 5. Оценка автоматически извлеченных слов\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdmXRFPdeWpa"
      },
      "source": [
        "def evaluate(y_pred, y_true):\n",
        "\n",
        "    y_pred = y_pred.apply(lambda x: set([''.join(w.split()) for w in x])).values  ## потому что там в оригинальных ключевых словах есть вещи типа oneofakind\n",
        "    y_true = y_true.apply(lambda x: set([''.join(w.split()) for w in x])).values\n",
        "\n",
        "    tp = np.apply_along_axis(func1d=lambda x: len(x[0]),\n",
        "                             axis=1,\n",
        "                             arr=np.expand_dims(y_pred & y_true, 1))\n",
        "\n",
        "    fp = np.apply_along_axis(func1d=lambda x: len(x[0]),\n",
        "                             axis=1,\n",
        "                             arr=np.expand_dims(y_pred - y_true, 1))\n",
        "    \n",
        "    fn = np.apply_along_axis(func1d=lambda x: len(x[0]),\n",
        "                             axis=1,\n",
        "                             arr=np.expand_dims(y_true - y_pred, 1))\n",
        "\n",
        "    macro_precision = (tp / (tp + fp + 1e-25)).mean()\n",
        "    macro_recall = (tp / (tp + fn)).mean()\n",
        "    macro_f1 =  (2 / (macro_recall ** -1 + macro_precision ** -1)).mean()\n",
        "\n",
        "    tp = tp.sum()\n",
        "    fp = fp.sum()\n",
        "    fn = fn.sum()\n",
        "\n",
        "    micro_precision = tp / (tp + fp) \n",
        "    micro_recall = tp / (tp + fn)\n",
        "    micro_f1 =  2 / (micro_recall ** -1 + micro_precision ** -1)\n",
        "\n",
        "    results = {'precision': {'macro': macro_precision,\n",
        "                             'micro': micro_precision},\n",
        "               'recall': {'macro': macro_recall,\n",
        "                          'micro': micro_recall},\n",
        "               'f1': {'macro': macro_f1,\n",
        "                      'micro': micro_f1}\n",
        "               }\n",
        "\n",
        "    return pd.DataFrame(results)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-AkrPQYiZ09"
      },
      "source": [
        "### 5.1 TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "MiHl867FfIIi",
        "outputId": "fbc05b57-bf09-42fc-c222-7668197ad7af"
      },
      "source": [
        "# без шаблонов\n",
        "evaluate(dataset.tfidf_1, dataset.target)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>macro</th>\n",
              "      <td>0.761291</td>\n",
              "      <td>0.462754</td>\n",
              "      <td>0.575617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>micro</th>\n",
              "      <td>0.688679</td>\n",
              "      <td>0.445122</td>\n",
              "      <td>0.540741</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       precision    recall        f1\n",
              "macro   0.761291  0.462754  0.575617\n",
              "micro   0.688679  0.445122  0.540741"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "mDupEskKfKJM",
        "outputId": "c7f25a98-a3aa-45a5-8050-d34e4cb86837"
      },
      "source": [
        "# с шаблонами\n",
        "evaluate(dataset.tfidf_1.apply(filter_kw), dataset.target)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>macro</th>\n",
              "      <td>0.797960</td>\n",
              "      <td>0.462754</td>\n",
              "      <td>0.585793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>micro</th>\n",
              "      <td>0.768421</td>\n",
              "      <td>0.445122</td>\n",
              "      <td>0.563707</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       precision    recall        f1\n",
              "macro   0.797960  0.462754  0.585793\n",
              "micro   0.768421  0.445122  0.563707"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "EsnyAwGdiygs",
        "outputId": "d3e5caf7-c982-4c88-f5cd-449f5948c841"
      },
      "source": [
        "# без шаблонов\n",
        "evaluate(dataset.tfidf_15, dataset.target)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>macro</th>\n",
              "      <td>0.918333</td>\n",
              "      <td>0.249496</td>\n",
              "      <td>0.392386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>micro</th>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.219512</td>\n",
              "      <td>0.336449</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       precision    recall        f1\n",
              "macro   0.918333  0.249496  0.392386\n",
              "micro   0.720000  0.219512  0.336449"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "pYunDsOvi0jv",
        "outputId": "8ed64428-1bab-4286-b23e-63177901d447"
      },
      "source": [
        "# с шаблонами\n",
        "evaluate(dataset.tfidf_15.apply(filter_kw), dataset.target)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>macro</th>\n",
              "      <td>0.941667</td>\n",
              "      <td>0.249496</td>\n",
              "      <td>0.394475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>micro</th>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.219512</td>\n",
              "      <td>0.349515</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       precision    recall        f1\n",
              "macro   0.941667  0.249496  0.394475\n",
              "micro   0.857143  0.219512  0.349515"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgLGfuiWipXA"
      },
      "source": [
        "### 5.2 TextRank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "_j9Lz71xho5n",
        "outputId": "72b074ba-8294-46d7-9edf-97c0f1f8affa"
      },
      "source": [
        "# без шаблонов\n",
        "evaluate(dataset.textrank, dataset.target)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>macro</th>\n",
              "      <td>0.132236</td>\n",
              "      <td>0.219391</td>\n",
              "      <td>0.165012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>micro</th>\n",
              "      <td>0.161290</td>\n",
              "      <td>0.243902</td>\n",
              "      <td>0.194175</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       precision    recall        f1\n",
              "macro   0.132236  0.219391  0.165012\n",
              "micro   0.161290  0.243902  0.194175"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "GSxBuqmTi9IJ",
        "outputId": "e2aa3fae-9d0b-4aa6-9912-d4bad910f621"
      },
      "source": [
        "# с шаблонами\n",
        "evaluate(dataset.textrank.apply(filter_kw), dataset.target)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>macro</th>\n",
              "      <td>0.148934</td>\n",
              "      <td>0.213835</td>\n",
              "      <td>0.175579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>micro</th>\n",
              "      <td>0.174888</td>\n",
              "      <td>0.237805</td>\n",
              "      <td>0.201550</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       precision    recall        f1\n",
              "macro   0.148934  0.213835  0.175579\n",
              "micro   0.174888  0.237805  0.201550"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0wNdn4ukRWa"
      },
      "source": [
        "### 5.3 BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "N5lIUEj8jZzd",
        "outputId": "cd020a70-aeea-4b7d-c86a-61b938fe7191"
      },
      "source": [
        "# без шаблонов\n",
        "evaluate(dataset.bert_4, dataset.target)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>macro</th>\n",
              "      <td>0.121515</td>\n",
              "      <td>0.173353</td>\n",
              "      <td>0.142878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>micro</th>\n",
              "      <td>0.119816</td>\n",
              "      <td>0.158537</td>\n",
              "      <td>0.136483</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       precision    recall        f1\n",
              "macro   0.121515  0.173353  0.142878\n",
              "micro   0.119816  0.158537  0.136483"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "WvKfB7JXkXTw",
        "outputId": "a98c2a23-8da5-49cb-efa7-5394f623dcfa"
      },
      "source": [
        "# с шаблонами\n",
        "evaluate(dataset.bert_4.apply(filter_kw), dataset.target)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>macro</th>\n",
              "      <td>0.194549</td>\n",
              "      <td>0.173353</td>\n",
              "      <td>0.183340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>micro</th>\n",
              "      <td>0.187050</td>\n",
              "      <td>0.158537</td>\n",
              "      <td>0.171617</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       precision    recall        f1\n",
              "macro   0.194549  0.173353  0.183340\n",
              "micro   0.187050  0.158537  0.171617"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "nutqyjRFkXFC",
        "outputId": "0a7901f8-f70d-43b5-ed71-0087bd8a2c6c"
      },
      "source": [
        "# без шаблонов\n",
        "evaluate(dataset.bert_5, dataset.target)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>macro</th>\n",
              "      <td>0.018750</td>\n",
              "      <td>0.024013</td>\n",
              "      <td>0.021058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>micro</th>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.027027</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       precision    recall        f1\n",
              "macro   0.018750  0.024013  0.021058\n",
              "micro   0.030303  0.024390  0.027027"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "cvR4MnrUkW0A",
        "outputId": "80941c1a-89bd-4710-990d-ae4352d9717e"
      },
      "source": [
        "# с шаблонами\n",
        "evaluate(dataset.bert_5.apply(filter_kw), dataset.target)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>macro</th>\n",
              "      <td>0.029762</td>\n",
              "      <td>0.024013</td>\n",
              "      <td>0.026580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>micro</th>\n",
              "      <td>0.049383</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.032653</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       precision    recall        f1\n",
              "macro   0.029762  0.024013  0.026580\n",
              "micro   0.049383  0.024390  0.032653"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5YnjnVYlWd3"
      },
      "source": [
        "# 6. Выводы и ошибки автоматического выделения:\n",
        "\n",
        "### 1. О методах:\n",
        "\n",
        "- Лучше всего с задачей в такой постановке справляется **TF-IDF**, что логично, учитывая, что такой алгоритм выдедения ключевых слов аналогичен ручному их выделению: простому записыванию самых частотных слов => и вывод **TF-IDF** наиболее похож на написанный вручную таргетный список слов, особенно с применением фильтрации по шаблонам\n",
        "\n",
        "- Затем следует алгоритм **TextRank**, хотя качество алгоритма сильно хуже, чем у TF-IDF, это как кажется можно объяснить используемыми метриками: точность, полнота и f-мера -- метрики каечства классификации, и поэтому не учитывают ранжирование ответов, в то время как алгоритм **TextRank** все же предназначен для ранжирования, а значит его работу более корректно оценивать при помощю метрик ранжирования (т.е. например `precision@k`, `recall@k`, `f1@k`)\n",
        "\n",
        "- Хуже всего с задачей справляется **BERT**, причем качество совсем плохое( Но это тоже можно объяснить немного странной работой алгоритма (в частности с `ngram_range`), что пришлось решать костылем => вывод не совсем точный (об этом в пункте 2)\n",
        "\n",
        "### 2. Качественная оценка:  \n",
        "Пункт 0: фильтрация по шаблонам помогает улучшить качество еа всех методах (хоть и незначительно), потому что алгоритмы выделяют сочетания слов, опираясь на частотность, а не смысл и логику, отчего получаются странные сочетания (см. ниже)\n",
        "\n",
        "\n",
        "**TF-IDF** в целом работает нормально, если смотреть на точность, что говорит о том, что он выделяет в целом логичные ключевые слова, однако полноста и f-мера желают лучшего, кажется, стоит посмотреть на порог вхождения ключевого слова в финальный список, в целом видно, что алгоритм выделяет намного меньше ключевых слов, чем, наверное, хотелось бы. Это, кмк, в том числе связано с тем, что в нашем случае корпус документов, на котором мы обучали наш векторайзер, очень маленький, поэтому некоторые слова получают довольно низкие скоры. Так что тут надо посмотреть на больший корпус текстов, чтобы понять, что поменять.\n",
        "\n",
        "Но **TF-IDF**, очевидно, выделяет наиболее похожие на выделенные человеком ключевые слова, и если посмотреть на вывод, то увидим это:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_QC-IYtljR_",
        "outputId": "6d6b3143-b35e-4241-e19b-9ed5e222014a"
      },
      "source": [
        "print('TARGET:', dataset.target[0])\n",
        "print('PRED:', dataset.tfidf_1[0])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TARGET: {'energy', 'grams', 'contain', 'fat', 'snacks', 'food', 'sugars', 'bars', 'bar', 'saturated', 'calories', 'syrup', 'nutrition', 'saturated fats', 'healthy', 'protein', 'energy bar'}\n",
            "PRED: {'saturated fat', 'energy', 'energy bars', 'grams', 'bars', 'bar', 'saturated', 'fat', 'contain', 'nutrition', 'protein'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncAHJV-Ap0Uz"
      },
      "source": [
        "**TextRank** выделяет больше слов, которые мне кажутся не совсем ключевыми: так в тексте 0 говорится про `energy bars`, в то время как алгоритм не выдает ни самого словосочетания, ни `energy`, ни `bars`, зато выделяет `rice syrup`, `story highlights` и другие слова и сочетания, не являющиеся самыми важными для описания текста.\n",
        "\n",
        "Не очень понятно, как это решать, поскольку эти результаты в целом кажутся странными, учитывая, что алгоритм работает на совтречаемости слов, а выделенные слова не очень частотные сами по себе (во всяком случае, как показалось мне), может быть проблема в конкретно этой имплементации.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBH8tc2Jn6pz",
        "outputId": "016ebe2e-f4fb-4960-ed13-bf53e676e2c9"
      },
      "source": [
        "print('TARGET:', dataset.target[0])\n",
        "print('PRED:', dataset.textrank[0])\n",
        "\n",
        "print()\n",
        "print(dataset.SUMMARY[0])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TARGET: {'energy', 'grams', 'contain', 'fat', 'snacks', 'food', 'sugars', 'bars', 'bar', 'saturated', 'calories', 'syrup', 'nutrition', 'saturated fats', 'healthy', 'protein', 'energy bar'}\n",
            "PRED: {'created', 'rice syrup', 'story highlights', 'replacement aim', 'convenient source', 'meal', 'meals', 'satisfy', 'satisfying', 'equal'}\n",
            "\n",
            "Story highlights Don't be fooled by the word \"energy\"Some energy bars contain as much saturated fat as a Snickers bar(CNN) Energy bars are a convenient source of nutrition and come in a wide variety of flavors to satisfy different palates.\n",
            "But, like many foods in a specific category, not all energy bars are created equal.\n",
            "For example, some bars covered in chocolate contain as much saturated fat as a Snickers bar; others contain almost as much sugar.\n",
            "Energy bars containing mostly fruit and nuts can serve as satisfying snacks.\n",
            "In general, try to aim for bars with less than 3 grams of saturated fat and at least 4 grams of fiber.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPx-9M35sEIe"
      },
      "source": [
        "**BERT** в отличие от остальных методов опирается не на статистику, а семантику текстов: конкретно эта имплементация сначала подбирает кандидаты через CountVectorizer, а затем ранжирует слова по косинусной близости вектора кандидата и вектора текста. Это, как мне кажется, и является слабостью алгоритма: он предпочитает выделять наиболее длинные ключевые фразы как более похожие и, как следствие, более информативные.\n",
        "\n",
        "Это самый главный минус выделения клбчевых слов при помощи берта (таким способом), мне кажется, для выделения ключевых слов удачнее было бы смотреть на матрицы внимания, которые по сути и выделяют самые важные слова в тексте, только надо понять, как аггрегировать информацию: брать за ключевые те слова к которым attend больше всего токенов (с самым большим весом) или еще как-то.\n",
        "\n",
        "\\+ из-за костыля с перебором `ngram_range`, чтобы получить хоть какие-то однословные ключевые фразы, выдается очень много схожих сочетаний: `bars`, `energy bars`, `energy bars containing`, `nutrition energy bars` и тд, что тоже неидеально\n",
        "\n",
        "При этом получается, что выделенные фразы не всегда логичные, и представляют не то чтобы связные куски текста, например `bars less grams`, `energy bars convinient` и тд."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsctvzCOv0HJ",
        "outputId": "8a790242-aaad-49b3-9c6e-fd22e9b60569"
      },
      "source": [
        "print('TARGET:', dataset.target[0])\n",
        "print('PRED:', dataset.bert_4[0])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TARGET: {'energy', 'grams', 'contain', 'fat', 'snacks', 'food', 'sugars', 'bars', 'bar', 'saturated', 'calories', 'syrup', 'nutrition', 'saturated fats', 'healthy', 'protein', 'energy bar'}\n",
            "PRED: {'snacks bar', 'bar protein carbohydrates', 'candy bar', 'nutrition energy', 'energy bars convenient', 'meals snacks bar', 'bars', 'nutrition energy bars', 'bars less grams', 'nutritional', 'energy bars contain', 'nutrition', 'calories bars consumed', 'calories bars', 'bars contain', 'bar protein', 'sugar granola bars', 'snacks', 'bars ingredients', 'bars consumed', 'energy bars', 'afford calories bars', 'energy bars containing', 'bar', 'granola bars'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS2mMciAAlvm"
      },
      "source": [
        ""
      ],
      "execution_count": 52,
      "outputs": []
    }
  ]
}