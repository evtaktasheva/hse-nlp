{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итоговый проект по автобрее\n",
    "### Выполнили:\n",
    "- Аксенова Анна\n",
    "- Волошина Екатерина\n",
    "- Кудрявцева Полина\n",
    "- Такташева Екатерина"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Этап 1: Сбор данных\n",
    "\n",
    "1. Корпус состоит из статей Википедии. \n",
    "\n",
    "2. Тексты фильтруются по некоторым паттернам, чтобы\n",
    "    - избежать ошибки сегментации предложений\n",
    "    - убрать предложения из списка литературы\n",
    "    - удалить лишние заголовки, не несущие особого веса\n",
    "    - удалить предложения с латинскими символами (потому что спасибо пайморфи)\n",
    "\n",
    "\n",
    "3. Предложения токенизируются (spacy) и размечаются pymorphy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скачиваем дамп википедии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2928,
     "status": "ok",
     "timestamp": 1599729295762,
     "user": {
      "displayName": "Екатерина Такташева",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgIKPqC7P_0vyGTNlqeEw42NhKLMzGw_JpDvx2A5A=s64",
      "userId": "05028020552383450813"
     },
     "user_tz": -180
    },
    "id": "LPHODwjW71OZ"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet corpuscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 568,
     "status": "ok",
     "timestamp": 1599729309193,
     "user": {
      "displayName": "Екатерина Такташева",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgIKPqC7P_0vyGTNlqeEw42NhKLMzGw_JpDvx2A5A=s64",
      "userId": "05028020552383450813"
     },
     "user_tz": -180
    },
    "id": "Q06Wca526qMr"
   },
   "outputs": [],
   "source": [
    "from corpuscula import corpus_utils\n",
    "\n",
    "\n",
    "# настройка каталога, в который скачается дамп википедии\n",
    "corpus_path = \"/Users/katya/УЧЕБА/Python/NLP/corpus/wiki\"\n",
    "corpus_utils.set_root_dir(corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 455,
     "status": "ok",
     "timestamp": 1599729316569,
     "user": {
      "displayName": "Екатерина Такташева",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgIKPqC7P_0vyGTNlqeEw42NhKLMzGw_JpDvx2A5A=s64",
      "userId": "05028020552383450813"
     },
     "user_tz": -180
    },
    "id": "HLWfsx_B6qMw"
   },
   "outputs": [],
   "source": [
    "root_dir = corpus_utils.get_root_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 571,
     "status": "ok",
     "timestamp": 1599729762316,
     "user": {
      "displayName": "Екатерина Такташева",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgIKPqC7P_0vyGTNlqeEw42NhKLMzGw_JpDvx2A5A=s64",
      "userId": "05028020552383450813"
     },
     "user_tz": -180
    },
    "id": "n9EmZy8Y6qM5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Wikipedia.RU\n",
      ">########] 100%                                                    \n",
      "done: 4097700193 bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/katya/УЧЕБА/Python/NLP/corpus/wiki/corpus/wikipedia_ru/ruwiki-latest-pages-articles.xml.bz2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from corpuscula import wikipedia_utils\n",
    "\n",
    "\n",
    "# скачивание википедии\n",
    "wikipedia_utils.download_wikipedia(lang=\"RU\", root_dir=root_dir, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 456,
     "status": "ok",
     "timestamp": 1599729764293,
     "user": {
      "displayName": "Екатерина Такташева",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgIKPqC7P_0vyGTNlqeEw42NhKLMzGw_JpDvx2A5A=s64",
      "userId": "05028020552383450813"
     },
     "user_tz": -180
    },
    "id": "g5z4TLLS6qNE"
   },
   "outputs": [],
   "source": [
    "from corpuscula import wikipedia_utils\n",
    "\n",
    "\n",
    "wik = wikipedia_utils.Wikipedia()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Грузим токенизатор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 897,
     "status": "ok",
     "timestamp": 1599729784243,
     "user": {
      "displayName": "Екатерина Такташева",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgIKPqC7P_0vyGTNlqeEw42NhKLMzGw_JpDvx2A5A=s64",
      "userId": "05028020552383450813"
     },
     "user_tz": -180
    },
    "id": "oP5QO1XWCsKG"
   },
   "outputs": [],
   "source": [
    "from spacy.lang.ru import Russian\n",
    "from spacy_russian_tokenizer import RussianTokenizer, MERGE_PATTERNS, SYNTAGRUS_RARE_CASES\n",
    "nlp = Russian()\n",
    "russian_tokenizer = RussianTokenizer(nlp, MERGE_PATTERNS + SYNTAGRUS_RARE_CASES)\n",
    "nlp.add_pipe(russian_tokenizer, name='russian_tokenizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чистим от цитат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rusenttokenize import ru_sent_tokenize\n",
    "from string import punctuation\n",
    "\n",
    "quotes = '«»”\"' + \"'\"\n",
    "\n",
    "def is_quote(sentence, quotes=quotes):\n",
    "    \"\"\"\n",
    "    check if any quotation mark is in an input sentence\n",
    "    \"\"\"\n",
    "    return True if any([quote in sentence for quote in quotes]) else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "От ошибок сегментации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_punct(sentence, punct_marks=punctuation+quotes):\n",
    "    \"\"\"\n",
    "    check if some punctuation patterns are in an input sentence\n",
    "    (gets rid of segmentation errors)\n",
    "    \"\"\"\n",
    "    return True if any([sentence.startswith(punct_mark) for punct_mark in punct_marks]) else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "От предложений с латинскими словами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_latin(sentence):\n",
    "    \"\"\"\n",
    "    checks if there is latin symbols in an input sentence\n",
    "    \"\"\"\n",
    "    return True if re.match('[A-z]', sentence) else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь применим это все к данным:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1599729785648,
     "user": {
      "displayName": "Екатерина Такташева",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgIKPqC7P_0vyGTNlqeEw42NhKLMzGw_JpDvx2A5A=s64",
      "userId": "05028020552383450813"
     },
     "user_tz": -180
    },
    "id": "MrmLvR-h6qNR"
   },
   "outputs": [],
   "source": [
    "def clean_article(a):\n",
    "    \"\"\"\n",
    "    strips text of headers, subheaders, etc.\n",
    "    \"\"\"\n",
    "    seg = [s for s in a.replace(\"\\xa0\", \" \").strip().split(\"\\n\\n\") if s and s.endswith(\".\")]\n",
    "    _s = []\n",
    "    for s in seg:\n",
    "        _s.extend(s.split('\\n'))\n",
    "    _s = [s for s in _s if 5 <= len(s.split()) and s[0].isupper() and s.endswith(\".\")]\n",
    "    return \" \".join(_s)\n",
    "\n",
    "\n",
    "def prepare_from_text(text):\n",
    "    \"\"\"\n",
    "    text --> sentences\n",
    "    filters sentences\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    sentences = [s.strip() for s in ru_sent_tokenize(text)]\n",
    "    for sentence in sentences:\n",
    "        _is_quote = is_quote(sentence)\n",
    "        _is_punct = is_punct(sentence)\n",
    "        _is_latin = is_latin(sentence)\n",
    "        if _is_quote or _is_punct or _is_latin:\n",
    "            continue\n",
    "\n",
    "        sent_in_words = [token.text for token in nlp(sentence) if token.text.isalpha()]\n",
    "        if 5 <= len(sent_in_words):\n",
    "            res.append(sentence)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Скачиваем статьи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 707,
     "status": "ok",
     "timestamp": 1599735400416,
     "user": {
      "displayName": "Екатерина Такташева",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgIKPqC7P_0vyGTNlqeEw42NhKLMzGw_JpDvx2A5A=s64",
      "userId": "05028020552383450813"
     },
     "user_tz": -180
    },
    "id": "sksrpbCA6qN0"
   },
   "outputs": [],
   "source": [
    "# инициализируем генератор статей\n",
    "gen = wik.articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24904122,
     "status": "error",
     "timestamp": 1599760304976,
     "user": {
      "displayName": "Екатерина Такташева",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgIKPqC7P_0vyGTNlqeEw42NhKLMzGw_JpDvx2A5A=s64",
      "userId": "05028020552383450813"
     },
     "user_tz": -180
    },
    "id": "gNgWNOOz6qN4",
    "outputId": "d1f09874-be7d-4314-f68a-278df14a0ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am here: /Users/katya/УЧЕБА/Python/NLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Wikipedia\n",
      "[> 999                                                            "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "print(\"I am here: %s\" % os.getcwd())\n",
    "c = 0\n",
    "\n",
    "with open(\"wiki.json\", \"a\", encoding=\"utf-8\") as f:\n",
    "    # индекс статьи (неупорядоченный), заголовок, текст статьи\n",
    "    for idx, title, article in gen:\n",
    "        c += 1\n",
    "        # ограничимся 1000 текстами\n",
    "        if c == 1000:\n",
    "            break\n",
    "\n",
    "        if not article or not title:\n",
    "            continue\n",
    "\n",
    "        a = clean_article(article)\n",
    "        ares = prepare_from_text(a)\n",
    "        \n",
    "        temp = {\n",
    "            \"title\": title,\n",
    "            \"res\": ares\n",
    "        }\n",
    "\n",
    "        f.write(\n",
    "            str(temp) + \"\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим скачанные данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 902,
     "status": "error",
     "timestamp": 1598308399324,
     "user": {
      "displayName": "Екатерина Такташева",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgIKPqC7P_0vyGTNlqeEw42NhKLMzGw_JpDvx2A5A=s64",
      "userId": "05028020552383450813"
     },
     "user_tz": -180
    },
    "id": "2qsPPiqB6qOD",
    "outputId": "65c74cdb-0efc-4fc8-bb0a-b41e2409b1da"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123f4401922b4bb2a7ce70e6d96fd2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "with open('wiki.json', 'r', encoding='utf-8') as fid:\n",
    "    for line in tqdm(fid):\n",
    "        text = json.loads(line.replace(\"'\", '\"'))\n",
    "        data.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "901"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Почему мы выбрали Pymorphy?\n",
    "Считаем, что нам больше важна полнота выдачи, чем ее точность, поэтому мы используем все варианты POS-тэгов, предлагаемые пайморфи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Приведем в порядок тэги:** немного обощим, убрав узкие группы, типа герундий (--> глагол), сранительная степень прилагательного (--> прилагательное) и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {\n",
    "    'NOUN': 'NOUN',\n",
    "    'ADJF': 'ADJ',\n",
    "    'ADJS': 'ADJ',\n",
    "    'COMP': 'COMP',\n",
    "    'VERB': 'VERB',\n",
    "    'INFN': 'VERB',\n",
    "    'PRTF': 'PTCP',\n",
    "    'PRTS': 'PTCP',\n",
    "    'GRND': 'VERB',\n",
    "    'NUMR': 'NUM',\n",
    "    'NPRO': 'PRON',\n",
    "    'PRED': 'VERB',\n",
    "    'PREP': 'PREP', \n",
    "    'CONJ': 'CONJ',\n",
    "    'PRCL': 'PART',\n",
    "    'INTJ': 'INTJ',\n",
    "    'ADVB': 'AD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Больше обработки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from urllib.parse import quote  # чтобы были красивые ссылочки\n",
    "\n",
    "\n",
    "\n",
    "def parse_analysis(analysis):\n",
    "    \"\"\"\n",
    "    returns the analysis of the parsed word, \n",
    "    formatted like: lemma1|lemma2, POS1|POS2\n",
    "    \"\"\"\n",
    "    tags = [(analysis[i].normal_form, \n",
    "             analysis[i].tag.POS) for i in range(len(analysis))]\n",
    "    tags = list(set(tags))\n",
    "    pos = [transform[t[1]] if t[1] is not None else 'UNK' for t in tags]\n",
    "    lemmas = [t[0] if not None else 'UNK' for t in tags]\n",
    "    return '|'.join(lemmas), '|'.join(pos)\n",
    "    \n",
    "\n",
    "def preprocess(sent):\n",
    "    \"\"\"\n",
    "    returns tokenized text (without punctuation marks)\n",
    "    and analysed text (lemmas and POS tags)\n",
    "    \"\"\"\n",
    "\n",
    "    tokenized = ' '.join([token.text for token in nlp(sent) if (token.text.isalpha() or \n",
    "                                                                '-' in token.text or \n",
    "                                                                '—' in token.text)])\n",
    "    lemmatized = []\n",
    "    pos_tagged = [] \n",
    "    \n",
    "    for token in tokenized.split():\n",
    "        analysis = morph.parse(token)\n",
    "        lemma, POS = parse_analysis(analysis)\n",
    "        lemmatized.append(lemma)\n",
    "        pos_tagged.append(POS)\n",
    "    return tokenized, ' '.join(lemmatized), ' '.join(pos_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем датасет: (ура)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(data):\n",
    "    \"\"\"\n",
    "    create dataframe\n",
    "    \"\"\"\n",
    "    df = []\n",
    "    for article in tqdm(data, total=len(data)):\n",
    "        title = article['title']\n",
    "        link = 'https://ru.wikipedia.org/wiki/{}'.format('_'.join(quote(title).split()))\n",
    "        for sent in article['res']:\n",
    "            tokenized, lemmatized, pos_tagged = preprocess(sent)\n",
    "            df.append((link, title, sent, tokenized, lemmatized, pos_tagged))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7162ee359540b0a8608220060f40ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = make_df(np.random.choice(np.array(df), 500, replace=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.DataFrame(df, columns=['source', 'title', 'sentence', 'tokenized', 'lemmatized', 'pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%...</td>\n",
       "      <td>Материальная точка</td>\n",
       "      <td>Материальная точка (частица)  — обладающее мас...</td>\n",
       "      <td>Материальная точка частица — обладающее массой...</td>\n",
       "      <td>материальный точка частица — обладать масса те...</td>\n",
       "      <td>ADJ NOUN NOUN UNK PTCP NOUN NOUN NOUN NOUN NOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%...</td>\n",
       "      <td>Материальная точка</td>\n",
       "      <td>Является простейшей физической моделью в механ...</td>\n",
       "      <td>Является простейшей физической моделью в механике</td>\n",
       "      <td>являться простой физический модель в|в механик...</td>\n",
       "      <td>VERB ADJ ADJ NOUN NOUN|PREP NOUN|NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%...</td>\n",
       "      <td>Материальная точка</td>\n",
       "      <td>Положение материальной точки в пространстве оп...</td>\n",
       "      <td>Положение материальной точки в пространстве оп...</td>\n",
       "      <td>положение материальный точка в|в пространство ...</td>\n",
       "      <td>NOUN ADJ NOUN NOUN|PREP NOUN VERB PART|CONJ|AD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%...</td>\n",
       "      <td>Материальная точка</td>\n",
       "      <td>В классической механике масса материальной точ...</td>\n",
       "      <td>В классической механике масса материальной точ...</td>\n",
       "      <td>в|в классический механика|механик масса матери...</td>\n",
       "      <td>NOUN|PREP ADJ NOUN|NOUN NOUN ADJ NOUN VERB ADJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%...</td>\n",
       "      <td>Материальная точка</td>\n",
       "      <td>Материальная точка — геометрическая точка, кот...</td>\n",
       "      <td>Материальная точка — геометрическая точка кото...</td>\n",
       "      <td>материальный точка — геометрический точка кото...</td>\n",
       "      <td>ADJ NOUN UNK ADJ NOUN ADJ PTCP NOUN|PREP NOUN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36827</th>\n",
       "      <td>36827</td>\n",
       "      <td>https://ru.wikipedia.org/wiki/1556%20%D0%B3%D0...</td>\n",
       "      <td>1556 год</td>\n",
       "      <td>Антоний Сийский — преподобный Русской церкви, ...</td>\n",
       "      <td>Антоний Сийский — преподобный Русской церкви о...</td>\n",
       "      <td>антоний|антония сийский — преподобный русский ...</td>\n",
       "      <td>NOUN|NOUN ADJ UNK ADJ ADJ NOUN NOUN INTJ|NOUN|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36828</th>\n",
       "      <td>36828</td>\n",
       "      <td>https://ru.wikipedia.org/wiki/1556%20%D0%B3%D0...</td>\n",
       "      <td>1556 год</td>\n",
       "      <td>Физули — Классик азербайджанской поэзии, сыгра...</td>\n",
       "      <td>Физули — Классик азербайджанской поэзии сыграв...</td>\n",
       "      <td>физули — классик|классика азербайджанский поэз...</td>\n",
       "      <td>NOUN UNK NOUN|NOUN ADJ NOUN PTCP ADJ NOUN|NOUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36829</th>\n",
       "      <td>36829</td>\n",
       "      <td>https://ru.wikipedia.org/wiki/1556%20%D0%B3%D0...</td>\n",
       "      <td>1556 год</td>\n",
       "      <td>Писал на азербайджанском, персидском и арабско...</td>\n",
       "      <td>Писал на азербайджанском персидском и арабском...</td>\n",
       "      <td>писать на|на|на азербайджанский персидский и|и...</td>\n",
       "      <td>VERB INTJ|PREP|PART ADJ ADJ INTJ|NOUN|PART|CON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36830</th>\n",
       "      <td>36830</td>\n",
       "      <td>https://ru.wikipedia.org/wiki/1556%20%D0%B3%D0...</td>\n",
       "      <td>1556 год</td>\n",
       "      <td>Хумаюн — второй из Великих Моголов, сын Бабура...</td>\n",
       "      <td>Хумаюн — второй из Великих Моголов сын Бабура ...</td>\n",
       "      <td>хумаюна — втора|второй иза|из великое|великий ...</td>\n",
       "      <td>NOUN UNK NOUN|ADJ NOUN|PREP NOUN|ADJ NOUN NOUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36831</th>\n",
       "      <td>36831</td>\n",
       "      <td>https://ru.wikipedia.org/wiki/1556%20%D0%B3%D0...</td>\n",
       "      <td>1556 год</td>\n",
       "      <td>Максим Грек — православный святой, переводчик ...</td>\n",
       "      <td>Максим Грек — православный святой переводчик и...</td>\n",
       "      <td>максима|максим грек — православный святой пере...</td>\n",
       "      <td>NOUN|NOUN NOUN UNK ADJ ADJ NOUN INTJ|NOUN|PART...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36832 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                             source  \\\n",
       "0               0  https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%...   \n",
       "1               1  https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%...   \n",
       "2               2  https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%...   \n",
       "3               3  https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%...   \n",
       "4               4  https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%...   \n",
       "...           ...                                                ...   \n",
       "36827       36827  https://ru.wikipedia.org/wiki/1556%20%D0%B3%D0...   \n",
       "36828       36828  https://ru.wikipedia.org/wiki/1556%20%D0%B3%D0...   \n",
       "36829       36829  https://ru.wikipedia.org/wiki/1556%20%D0%B3%D0...   \n",
       "36830       36830  https://ru.wikipedia.org/wiki/1556%20%D0%B3%D0...   \n",
       "36831       36831  https://ru.wikipedia.org/wiki/1556%20%D0%B3%D0...   \n",
       "\n",
       "                    title                                           sentence  \\\n",
       "0      Материальная точка  Материальная точка (частица)  — обладающее мас...   \n",
       "1      Материальная точка  Является простейшей физической моделью в механ...   \n",
       "2      Материальная точка  Положение материальной точки в пространстве оп...   \n",
       "3      Материальная точка  В классической механике масса материальной точ...   \n",
       "4      Материальная точка  Материальная точка — геометрическая точка, кот...   \n",
       "...                   ...                                                ...   \n",
       "36827            1556 год  Антоний Сийский — преподобный Русской церкви, ...   \n",
       "36828            1556 год  Физули — Классик азербайджанской поэзии, сыгра...   \n",
       "36829            1556 год  Писал на азербайджанском, персидском и арабско...   \n",
       "36830            1556 год  Хумаюн — второй из Великих Моголов, сын Бабура...   \n",
       "36831            1556 год  Максим Грек — православный святой, переводчик ...   \n",
       "\n",
       "                                               tokenized  \\\n",
       "0      Материальная точка частица — обладающее массой...   \n",
       "1      Является простейшей физической моделью в механике   \n",
       "2      Положение материальной точки в пространстве оп...   \n",
       "3      В классической механике масса материальной точ...   \n",
       "4      Материальная точка — геометрическая точка кото...   \n",
       "...                                                  ...   \n",
       "36827  Антоний Сийский — преподобный Русской церкви о...   \n",
       "36828  Физули — Классик азербайджанской поэзии сыграв...   \n",
       "36829  Писал на азербайджанском персидском и арабском...   \n",
       "36830  Хумаюн — второй из Великих Моголов сын Бабура ...   \n",
       "36831  Максим Грек — православный святой переводчик и...   \n",
       "\n",
       "                                              lemmatized  \\\n",
       "0      материальный точка частица — обладать масса те...   \n",
       "1      являться простой физический модель в|в механик...   \n",
       "2      положение материальный точка в|в пространство ...   \n",
       "3      в|в классический механика|механик масса матери...   \n",
       "4      материальный точка — геометрический точка кото...   \n",
       "...                                                  ...   \n",
       "36827  антоний|антония сийский — преподобный русский ...   \n",
       "36828  физули — классик|классика азербайджанский поэз...   \n",
       "36829  писать на|на|на азербайджанский персидский и|и...   \n",
       "36830  хумаюна — втора|второй иза|из великое|великий ...   \n",
       "36831  максима|максим грек — православный святой пере...   \n",
       "\n",
       "                                                     pos  \n",
       "0      ADJ NOUN NOUN UNK PTCP NOUN NOUN NOUN NOUN NOU...  \n",
       "1                  VERB ADJ ADJ NOUN NOUN|PREP NOUN|NOUN  \n",
       "2      NOUN ADJ NOUN NOUN|PREP NOUN VERB PART|CONJ|AD...  \n",
       "3      NOUN|PREP ADJ NOUN|NOUN NOUN ADJ NOUN VERB ADJ...  \n",
       "4      ADJ NOUN UNK ADJ NOUN ADJ PTCP NOUN|PREP NOUN ...  \n",
       "...                                                  ...  \n",
       "36827  NOUN|NOUN ADJ UNK ADJ ADJ NOUN NOUN INTJ|NOUN|...  \n",
       "36828  NOUN UNK NOUN|NOUN ADJ NOUN PTCP ADJ NOUN|NOUN...  \n",
       "36829  VERB INTJ|PREP|PART ADJ ADJ INTJ|NOUN|PART|CON...  \n",
       "36830  NOUN UNK NOUN|ADJ NOUN|PREP NOUN|ADJ NOUN NOUN...  \n",
       "36831  NOUN|NOUN NOUN UNK ADJ ADJ NOUN INTJ|NOUN|PART...  \n",
       "\n",
       "[36832 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще немного пообрабатываем (спасибо пайморфи)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rid_of_iza(sent):\n",
    "    new = []\n",
    "    for word in sent.split():\n",
    "        if word == 'иза':\n",
    "            word = 'из'\n",
    "        new.append(word)\n",
    "    return ' '.join(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized'] = df['lemmatized'].apply(get_rid_of_iza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну и сохраним:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('corpora_data.csv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "wiki_prep.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
