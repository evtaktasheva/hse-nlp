{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1: Тональный классификатор\n",
    "### Такташева Катя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pprint import pprint\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "\n",
    "session = requests.session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get films' ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_film_id(film):\n",
    "    link = re.search('href=\"/film/(\\d+?)/\"', str(film)).group(1)\n",
    "    return link\n",
    "\n",
    "\n",
    "def get_films(pn):\n",
    "    ids = []\n",
    "    page = session.get(f'https://www.kinopoisk.ru/popular/films/?page={pn}&tab=all').text\n",
    "    time.sleep(random.uniform(1.1, 5.2))\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    films = soup.find_all('div', {'class':'desktop-rating-selection-film-item'})\n",
    "    \n",
    "    for film in films:\n",
    "        ids.append(get_film_id(film))\n",
    "        \n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832a724f19a8445798723dcca575bf74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "films = []\n",
    "for pn in tqdm(range(1, 35)):\n",
    "    time.sleep(random.uniform(1.1, 8.2))\n",
    "    ids = get_films(pn)\n",
    "    films.extend(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(films)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.kinopoisk.ru/film/326/reviews'\n",
    "СHROME_PATH = os.path.join(os.getcwd(), 'chromedriver')\n",
    "DRIVER = webdriver.Chrome(executable_path=СHROME_PATH)\n",
    "SLEEP_TIME = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://www.kinopoisk.ru/film/{}/reviews'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(link, id):\n",
    "    film_reviews = {'film_id': id,\n",
    "                   'pos': [],\n",
    "                   'neg': []}\n",
    "    plink = link.format(id)\n",
    "    page = DRIVER.get(plink)\n",
    "    time.sleep(random.uniform(1.1, 5.2))\n",
    "    for tp in ['pos', 'neg']:\n",
    "        try:\n",
    "            DRIVER.find_element_by_class_name(tp).find_element_by_tag_name('a').click()\n",
    "            time.sleep(random.uniform(1.1, 5.2))\n",
    "            reviews = DRIVER.find_elements_by_class_name('_reachbanner_')\n",
    "            for idx, rev in enumerate(reviews):\n",
    "                film_reviews[tp].append(rev.text)\n",
    "        except:  # если нет отзывов\n",
    "            pass\n",
    "    return film_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619910130cd94fa2a787aa40e870ab0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reviews = []\n",
    "for film_id in tqdm(films):\n",
    "    data = get_reviews(link, film_id)\n",
    "    reviews.append( data)\n",
    "DRIVER.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('reviews.json', 'w', encoding='utf-8') as fid:\n",
    "    fid.write(json.dumps(reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('reviews.json', 'r', encoding='utf-8') as fid:\n",
    "    reviews = json.loads(fid.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Spacy for Russian to tokenize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.ru import Russian\n",
    "from spacy_russian_tokenizer import RussianTokenizer, MERGE_PATTERNS, SYNTAGRUS_RARE_CASES\n",
    "nlp = Russian()\n",
    "russian_tokenizer = RussianTokenizer(nlp, MERGE_PATTERNS + SYNTAGRUS_RARE_CASES)\n",
    "nlp.add_pipe(russian_tokenizer, name='russian_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    words = []\n",
    "    for word in nlp(text):\n",
    "        lemma = morph.parse(word.text)[0].normal_form\n",
    "        words.append(lemma)\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "def split_data(data):\n",
    "    new_data = []\n",
    "    for film in tqdm(data):\n",
    "        for review in film['pos']:\n",
    "            new_data.append((film['film_id'], lemmatize(review), 'pos'))\n",
    "        for review in film['neg']:\n",
    "            new_data.append((film['film_id'], lemmatize(review), 'neg'))\n",
    "            \n",
    "    new_data = shuffle(pd.DataFrame(np.array(new_data), columns=['film_id', 'text', 'class']))\n",
    "    \n",
    "    train, test = np.split(new_data.sample(frac=1), [int(.80*len(new_data))])\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6ba6f1972940208523d5948709b122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train, test = split_data(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sentences: 11494\n",
      "Test sentences: 2874\n"
     ]
    }
   ],
   "source": [
    "print(f'Train sentences: {len(train)}')\n",
    "print(f'Test sentences: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film_id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6167</th>\n",
       "      <td>103734</td>\n",
       "      <td>я стыдно признаться , что данный мультипликаци...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12660</th>\n",
       "      <td>363</td>\n",
       "      <td>плохо понимать , как писать рецензия на этот ф...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8379</th>\n",
       "      <td>491724</td>\n",
       "      <td>это уже восьмой фильм от режиссёр дэвид финчер...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3090</th>\n",
       "      <td>1164484</td>\n",
       "      <td>в маленький город на граница безымянный импери...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5709</th>\n",
       "      <td>104992</td>\n",
       "      <td>довольно странно писать свой мнение о фильм бо...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       film_id                                               text class\n",
       "6167    103734  я стыдно признаться , что данный мультипликаци...   pos\n",
       "12660      363  плохо понимать , как писать рецензия на этот ф...   pos\n",
       "8379    491724  это уже восьмой фильм от режиссёр дэвид финчер...   pos\n",
       "3090   1164484  в маленький город на граница безымянный импери...   pos\n",
       "5709    104992  довольно странно писать свой мнение о фильм бо...   neg"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    6458\n",
       "neg    5036\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    1607\n",
       "neg    1267\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tonality dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "ru_stopwords = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, lemmatize=False):\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        if word.isalpha() and word not in ru_stopwords:\n",
    "            if lemmatize:\n",
    "                word = morph.parse(word)[0].normal_form\n",
    "            words.append(word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(pos_words, neg_words):\n",
    "    tone_dict = {}\n",
    "    for word in pos_words:\n",
    "        tone_dict[word] = 'pos'\n",
    "    for word in neg_words:\n",
    "        tone_dict[word] = 'neg'\n",
    "        \n",
    "    return tone_dict\n",
    "\n",
    "\n",
    "def get_tone_words(data, min_count=10):\n",
    "    \n",
    "    dic = {'pos': Counter(),\n",
    "           'neg': Counter()}\n",
    "    \n",
    "    print('Computing frequency dict...')\n",
    "    for idx, review in tqdm(data.iterrows(), total=len(data)):\n",
    "        dic[review['class']] += Counter(preprocess(review['text']))\n",
    "            \n",
    "    negative = set([i[0] for i in dic['neg'].most_common() if i[1] >= min_count])\n",
    "    positive = set([i[0] for i in dic['pos'].most_common() if i[1] >= min_count])\n",
    "    \n",
    "    intersect = positive.intersection(negative)\n",
    "    for i in intersect:\n",
    "        positive.discard(i)\n",
    "        negative.discard(i)\n",
    "    \n",
    "    #min_size = min((len(positive), len(negative)))  # по-хорошему надо сравнять размеры классов, но\n",
    "    #positive = list(positive)[:min_size]            # т.к. у нас довольно мало данных это сильно уменьшает\n",
    "    #negative = list(negative)[:min_size]            # размер словаря и => точность классификатора\n",
    "    \n",
    "    print(f'No intersection: {set(positive).isdisjoint(set(negative))}')\n",
    "    print(f'Positive: {len(positive)}')\n",
    "    print(f'Negative: {len(negative)}')\n",
    "                   \n",
    "    return create_dict(positive, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing frequency dict...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11494.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No intersection: True\n",
      "Positive: 1066\n",
      "Negative: 176\n"
     ]
    }
   ],
   "source": [
    "tone_dict = get_tone_words(train, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(review):\n",
    "    review_class = Counter()\n",
    "    words = preprocess(review)\n",
    "    for word in words:\n",
    "        if word in tone_dict:\n",
    "            review_class[tone_dict[word]] += 1 \n",
    "    return review_class.most_common()[0][0] if len(review_class) > 0 else 'pos'\n",
    "\n",
    "\n",
    "def make_predictions(test):\n",
    "    predictions = []\n",
    "    for idx, x in test.iterrows():\n",
    "        pred = classify_review(x['text'])\n",
    "        predictions.append(pred)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.592553931802366\n"
     ]
    }
   ],
   "source": [
    "prediction = make_predictions(test[['film_id', 'text']])\n",
    "print(accuracy_score(prediction, test[['class']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements\n",
    "\n",
    "Самое простое:\n",
    "1. **Больше данных**\n",
    "    - Сейчас данных довольно мало и, поскольку (например, в сравнении с задачей по определению языка) слова менее distinct в классах, получается маленький словарь, не все слова находятся и от этого страдает доля верных ответов :( \n",
    "\n",
    "\n",
    "2. **Баланс классов**\n",
    "    - **2.1** При разделении выборки на \"обучающую\" и тест, для лучшего результата нужно сравнять баланс классов, чтобы не получалось, что положительных отзывов в 5 раз больше, чем отрицательных. В таком случае и в словаре тональных слов один класс будет заметно преобладать, поэтому такая классификация, как мы делаем, будет с большей вероятностью выдавать именно преобладающий класс (см. ниже)\n",
    "    - **2.2** Эту проблему можно решить и при создании самого словаря: если мы выравниваем размеры уже готового словаря, то тогда у нас не будет перевеса одного класса, но тут снова упираемся в проблему 1: для этого надо больше данных\n",
    "\n",
    "3. **Подбор гиперпараметров**\n",
    "    - Еще один способ для улучшения качества - подбор подходящих гиперпараметров, в нашем случае - минимальное количество вхождения слов в словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def balance_classes(data):\n",
    "    balanced = []\n",
    "    classes = data['class'].unique().tolist()\n",
    "    size = data['class'].value_counts().min()\n",
    "    for cl in classes:\n",
    "        balanced.append(data[data['class']==cl].sample(size))\n",
    "    return shuffle(pd.concat(balanced, ignore_index=True))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_b = balance_classes(train)\n",
    "test_b = balance_classes(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    5036\n",
       "neg    5036\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_b['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    1267\n",
       "pos    1267\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_b['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing frequency dict...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c48a8a2f8d246499ac0c855cb8b0675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10072.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No intersection: True\n",
      "Positive: 240\n",
      "Negative: 204\n"
     ]
    }
   ],
   "source": [
    "tone_dict = get_tone_words(train_b, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6669297553275454\n"
     ]
    }
   ],
   "source": [
    "prediction = make_predictions(test_b[['film_id', 'text']])\n",
    "print(accuracy_score(prediction, test_b[['class']]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
